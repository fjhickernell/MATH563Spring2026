


import math
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
import classlib as cl

%matplotlib inline

rng = np.random.default_rng(20251222)

cl.nbviz.init(use_tex=True)
cl.nbviz.configure(figpath="approval_rating_figures", savefigs=True)





# Parameters (edit as desired)
n = 1500          # sample size
p_true = 0.36    # "true" approval probability (for simulation)
alpha = 0.05     # 95% CI

# Simulate survey responses: 1 = Yes/Approve, 0 = No/Disapprove
y = rng.binomial(n=1, p=p_true, size=n)
tot = int(y.sum())          # number of Yes responses
phat = tot / n              # sample proportion

n, tot, phat






counts = np.array([n - tot, tot])
labels = ["No", "Yes"]

fig, ax = plt.subplots()
bars = ax.bar(labels, counts, color=cl.nbviz.tol_colors(len(labels)))
ax.set_title("Simulated survey responses")
ax.set_ylabel("Count")
for b in bars:
    ax.text(b.get_x() + b.get_width()/2, b.get_height(), f"{int(b.get_height())}",
            ha="center", va="bottom")
plt.show()









# 1) Exact binomial confidence interval (Clopper–Pearson-style)
bt = stats.binomtest(tot, n=n, p=0.5)  # p is irrelevant for the CI call; scipy uses tot,n
ci_exact = bt.proportion_ci(confidence_level=1-alpha, method="exact")

# 2) CLT / Wald interval
z = stats.norm.ppf(1 - alpha/2)
se_hat = math.sqrt(phat * (1 - phat) / n)
ci_clt = (max(0.0, phat - z * se_hat), min(1.0, phat + z * se_hat))





def fmt_pct(x):
    return f"{100*x:.1f}%"

print(f"Sample size, n = {n}")
print(f"Yes count = {tot}")
print(f"Point estimate phat = {phat:.4f} ({fmt_pct(phat)})")
print()
print(f"{int((1-alpha)*100)}% exact (binomial) CI: [{ci_exact.low:.4f}, {ci_exact.high:.4f}]  "
      f"= [{fmt_pct(ci_exact.low)}, {fmt_pct(ci_exact.high)}]")
print(f"{int((1-alpha)*100)}% CLT (Wald) CI:       [{ci_clt[0]:.4f}, {ci_clt[1]:.4f}]  "
      f"= [{fmt_pct(ci_clt[0])}, {fmt_pct(ci_clt[1])}]")






# Optional: Monte Carlo check of approximate coverage (quick demo).
# Increase reps for a more stable estimate.
reps = 5000
p0 = p_true

def ci_exact_for_k_vec(k, n, alpha=0.05):
    """
    Exact (Clopper–Pearson) CI for Bernoulli proportion.
    Vectorized interface (internally loops; exact CI is scalar).
    """
    k = np.asarray(k, dtype=int)
    lo = np.empty_like(k, dtype=float)
    hi = np.empty_like(k, dtype=float)
    for i, ki in np.ndenumerate(k):
        bt = stats.binomtest(int(ki), n=n, p=0.5)
        ci = bt.proportion_ci(confidence_level=1 - alpha, method="exact")
        lo[i], hi[i] = ci.low, ci.high
    return lo, hi

def wald_ci_for_k(k, n, alpha=0.05):
    """
    Wald (CLT) confidence interval for a Bernoulli proportion,
    based on counts k out of n. Vectorized and clipped to [0,1].
    """
    k = np.asarray(k, dtype=float)
    ph = k / n
    z = stats.norm.ppf(1 - alpha / 2)
    se = np.sqrt(ph * (1 - ph) / n)
    lo = np.clip(ph - z * se, 0.0, 1.0)
    hi = np.clip(ph + z * se, 0.0, 1.0)
    return lo, hi

ks = rng.binomial(n=n, p=p0, size=reps)
lo_exact, hi_exact = ci_exact_for_k_vec(ks, n, alpha=alpha)
lo_wald,  hi_wald  = wald_ci_for_k(ks, n, alpha=alpha)
cover_exact = np.mean((lo_exact <= p0) & (p0 <= hi_exact))
cover_wald  = np.mean((lo_wald  <= p0) & (p0 <= hi_wald))

print(f"Monte Carlo estimated coverage at p={p0:.3f}, n={n}, reps={reps}:")
print(f"  Exact CI coverage ≈ {cover_exact:.3f}")
print(f"  CLT/Wald coverage ≈ {cover_wald:.3f}")





def simulate_wald_coverage(R, n, p, *, rng, alpha=0.05):
    y = rng.binomial(1, p, size=(R, n))
    k = y.sum(axis=1)
    lo, hi = wald_ci_for_k(k, n, alpha=alpha)
    phat = k / n
    cover = (lo <= p) & (p <= hi)
    return phat, lo, hi, cover

phat, lo, hi, cover = simulate_wald_coverage(reps, n, p_true, rng=rng, alpha=alpha)
coverage = cover.mean()





fig, ax = plt.subplots()

ax.hist(phat, bins="auto", density=True, alpha=0.85, color=cl.nbviz.tol_colors(2)[0])
ax.axvline(p_true, linestyle="--", linewidth=2, color=cl.nbviz.tol_colors(2)[1])

ax.set_title(fr"Repeated sampling: $\hat p$ from $R={reps}$ samples of size $n={n}$")
ax.set_xlabel(r"$\hat p$")
ax.set_ylabel("Density")

ax.text(
    0.02, 0.98,
    fr"True $p={p_true}$" 
    "\n" 
    r"CLT 95\% CI empirical" 
    "\n" 
    fr" coverage: {coverage:.3f}",
    transform=ax.transAxes,
    va="top",
    fontsize=16,       
    linespacing=1.4    
)





K = 250  #number to show
idx = np.arange(K)
hit = cover[:K]
miss = ~hit
fig, ax = plt.subplots(figsize=(7.5, 5.5))

# Hits: solid gray
ax.hlines(
    idx[hit],
    lo[:K][hit],
    hi[:K][hit],
    lw=1.5,
    color=colors["gray"],
    alpha=1.0,
    label="CI contains true $p$"
)

# Misses: dashed blue
ax.hlines(
    idx[miss],
    lo[:K][miss],
    hi[:K][miss],
    lw=2.5,
    linestyle="--",
    color=colors["blue"],
    alpha=1.0,
    label="CI misses true $p$"
)

# True parameter
ax.axvline(p_true, linestyle="--", color="black", lw=1.5)
ax.set_title(fr"First $K={K}$ CLT 95\% confidence intervals")
ax.set_xlabel("$p$")
ax.set_ylabel("replicate index")
ax.set_ylim(-2, K+2)

# Legend outside to the right
ax.legend(
    loc="center left",
    bbox_to_anchor=(1.02, 0.5),
    frameon=False
)

# Make room for the legend
fig.subplots_adjust(right=0.75)



